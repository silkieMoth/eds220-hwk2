{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hwk2-task3-aqi.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Visualizing AQI during the 2017 Thomas Fire in Santa Barbara County\n",
    "\n",
    "## Instructions \n",
    "\n",
    "- First, update the following cell to have a link to *your* Homework 2 GitHub repository:\n",
    "\n",
    "**UPDATE THIS LINK**\n",
    "https://github.com/MEDS-eds-220/eds220-hwk2\n",
    "\n",
    "\n",
    "- Review the [complete rubric for this task](https://docs.google.com/document/d/1x0BoU6IH4cnOR1-n7i9CYQ9wUC37yDpYlQ4j6rCfcsU/edit?tab=t.0) before starting.\n",
    "\n",
    "- **Meaningful commits should be made every time you finish a major step.** We'll check your repository and view the commit history.\n",
    "\n",
    "- **Every code cell should have a comment.** Err on the side of commenting too much for now. Comments should follow best practices.\n",
    "\n",
    "- **Do not update the top cell with the `otter` import**, this is used internally for grading.\n",
    "\n",
    "## About the data\n",
    "\n",
    "In this task you will use [Air Quality Index (AQI)](https://www.airnow.gov/aqi/aqi-basics/) data from the [US Environmental Protection Agency](https://www.epa.gov) to visualize the impact on the AQI of the 2017 [Thomas Fire](https://en.wikipedia.org/wiki/Thomas_Fire) in Santa Barbara County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPLETE WORKFLOW\n",
    "\n",
    "You will use the next code cell to complete the last exercise in the task. Leave it blank for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "a. Read the [Air Quality Index (AQI) Basics](https://www.airnow.gov/aqi/aqi-basics/) from the AirNow.gov portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Go to [EPA's website on Air Quality Data Collected at Outdoor Monitors Across the US](https://www.epa.gov/outdoor-air-quality-data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Under \"Donwload Data\", click on \"Pre-generated Data Files\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Read the \"About the data\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "a. Back in the \"Pre-generated Data Files\" site, click on \"Tables of Daily AQI\".\n",
    "\n",
    "b. Copy the URL to the 2017 Daily AQI **by County** ZIP file `daily_aqi_by_county_2017.zip`\n",
    "\n",
    "Notice we'll be reding the data directly from its ZIP file link. This ZIP file contains a single CSV that has been compressed to save space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "c. In the next code cell read in the data from the URL using the [`pd.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function with the `compression='zip'` parameter added and store it as `aqi_17`. \n",
    "\n",
    "d. In the same cell, read in the data for the 2018 Daily AQI by County ZIP file and store it as `aqi_18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in data\n",
    "url_17 = \"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\"\n",
    "url_18 = \"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\"\n",
    "\n",
    "aqi_17 = pd.read_csv(url_17, compression = 'zip')\n",
    "aqi_18 = pd.read_csv(url_18, compression = 'zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3\n",
    "a. and b. Use the next two code cells to look at the head of both data frames. Store your results in `aqi_17_head` and `aqi_18_head`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a.\n",
    "aqi_17_head = aqi_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b.\n",
    "aqi_18_head = aqi_18.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "c. Use this code cell to make some other preliminary data exploration of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns, nulls and data types \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 326801 entries, 0 to 326800\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   State Name                 326801 non-null  object\n",
      " 1   county Name                326801 non-null  object\n",
      " 2   State Code                 326801 non-null  int64 \n",
      " 3   County Code                326801 non-null  int64 \n",
      " 4   Date                       326801 non-null  object\n",
      " 5   AQI                        326801 non-null  int64 \n",
      " 6   Category                   326801 non-null  object\n",
      " 7   Defining Parameter         326801 non-null  object\n",
      " 8   Defining Site              326801 non-null  object\n",
      " 9   Number of Sites Reporting  326801 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 24.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327541 entries, 0 to 327540\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   State Name                 327541 non-null  object\n",
      " 1   county Name                327541 non-null  object\n",
      " 2   State Code                 327541 non-null  int64 \n",
      " 3   County Code                327541 non-null  int64 \n",
      " 4   Date                       327541 non-null  object\n",
      " 5   AQI                        327541 non-null  int64 \n",
      " 6   Category                   327541 non-null  object\n",
      " 7   Defining Parameter         327541 non-null  object\n",
      " 8   Defining Site              327541 non-null  object\n",
      " 9   Number of Sites Reporting  327541 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 25.0+ MB\n",
      "\n",
      "\n",
      "unique value counts by variable \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2017',\n",
       " State Name                     54\n",
       " county Name                   796\n",
       " State Code                     54\n",
       " County Code                   160\n",
       " Date                          365\n",
       " AQI                           341\n",
       " Category                        6\n",
       " Defining Parameter              5\n",
       " Defining Site                2133\n",
       " Number of Sites Reporting      35\n",
       " dtype: int64,\n",
       " '',\n",
       " '2018',\n",
       " State Name                     54\n",
       " county Name                   793\n",
       " State Code                     54\n",
       " County Code                   160\n",
       " Date                          365\n",
       " AQI                           300\n",
       " Category                        6\n",
       " Defining Parameter              5\n",
       " Defining Site                2105\n",
       " Number of Sites Reporting      35\n",
       " dtype: int64]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"columns, nulls and data types \\n\")\n",
    "aqi_17.info()\n",
    "aqi_18.info()\n",
    "print(f'\\n')\n",
    "print(f\"unique value counts by variable \\n\")\n",
    "['2017',\n",
    " aqi_17.nunique(),\n",
    " '',\n",
    " '2018',\n",
    " aqi_18.nunique()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "d. Use this markdown cell to explain why you decided to do the exploration in c. and what information you obtained from doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a combination of `info()` and `unique()`, I get all the information I need to get a basic understanding of the variables I'm working with. I can see that:\n",
    " - there are zero null values to mess up my analysis\n",
    " - the data types, which tells me what types of analysis I can do on which variable\n",
    " - which variables are likely categorical and which are likely numeric\n",
    " - which variables in which I might need to edit the data type of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4\n",
    "We currently have two separate data frames. For this exercise we will need to \"glue\" them one on top of the other. The `pandas` function `pd.concat()` can achieve this. \n",
    "\n",
    "Pass `[aqi_17, aqi_18]` as the input of `pd.concat()` and store the output as  `aqi`.  \n",
    "In the next line run `aqi`.\n",
    "\n",
    "NOTE: When we concatenate data frames like this, without any extra parameters for `pd.concat()` the indices for the two dataframes are just \"glued together\", the index of the resulting dataframe is not updated to start from 0. Notice the mismatch between the index of `aqi` and the number of rows i the complete data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.7.13/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1833991/4177208302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maqi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maqi_17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maqi_18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maqi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.7.13/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.7.13/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.7.13/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             raise TypeError(\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0;34m\"first argument must be an iterable of pandas \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                 \u001b[0;34mf'objects, you passed an object of type \"{type(objs).__name__}\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "aqi = ...\n",
    "aqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5\n",
    "\n",
    "Run the following code cell and use the next markdown cell to give a line by line explanation of the code below the comment \"#Simplify column names\". You might need to look up the `pandas` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initial column names: notice caps and spaces (difficult to work with!)\n",
    "print(aqi.columns, '\\n')\n",
    "\n",
    "# Simplify column names\n",
    "aqi.columns = (aqi.columns\n",
    "                  .str.lower()\n",
    "                  .str.replace(' ','_')\n",
    "                )\n",
    "print(aqi.columns, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6\n",
    "In the next code cell:\n",
    "\n",
    "a. Select only data from `Santa Barbara` county and store it in a new variable `aqi_sb`.\n",
    "\n",
    "b. Remove the `state_name`, `county_name`, `state_code` and `county_code` columns from `aqi_sb`.\n",
    "\n",
    "Your dataframe should have the following columns in this order: `date`, `aqi`, `category`, `defining_parameter`, `defining_stie`, `number_of_sites_reporting`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aqi_sb = ...\n",
    "aqi_sb = ...\n",
    "aqi_sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    " \n",
    "c. What is the data type of the `date` column? Store your answer in the `date_type` variable. Your answer should contain the type for the **date column only**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_type = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7\n",
    "In the following cell:\n",
    "1. Update the date column of `aqi_sb` to be a `pandas.datetime` object.\n",
    "2. Update the index of `aqi_sb` to be the `date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "aqi_sb.date = ...\n",
    "aqi_sb = ...\n",
    "aqi_sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 8\n",
    "In the next cell we will calculate an average over a [rolling window](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.rolling.html) using the `rolling()`method for `pandas.Series`:\n",
    "\n",
    "- `rolling()` is a lazy method, so we need to specify what we want to calculate over each window before it does something. \n",
    "- in this example we use the aggregator function `mean()` to calculate the average over each window\n",
    "- the parameter '5D' indicates we want the window for our rolling average to be 5 days. \n",
    "- we get a `pandas.Series` as ouput\n",
    "\n",
    "Store your answer in the `rolling_average` variable. You should have two columns in your series, `date` and the averages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate AQI rolling average over 5 days\n",
    "rolling_average = ...\n",
    "rolling_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 9 \n",
    "\n",
    "Without creating any new variables, add the mean of the AQI over a 5-day rolling window as a new column named `five_day_average` to the `aqi_sb` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10\n",
    "Make a line plot showing both the daily AQI and the 5-day average (5-day average on top of the AQI). Make necessary updates for the plot to be accurate, informative, and polished, even if simple. You're welcome to use plotting methods and packages beyond what we have covered in class! \n",
    "\n",
    "Can you see the AQI going up during the Thomas Fire in December 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 10\n",
    "\n",
    "Collect all the relevant code into the first blank cell of the notebook titled \"COMPLETE WORKFLOW\". This single cell will have the end-to-end workflow: from importing libraries and loading the data, to producing the graph. The *only* ouput of this cell should be the graph you produced in the previous exercise. Further guidance on what to include in this final workflow is in the [assignment rubric](https://docs.google.com/document/d/1x0BoU6IH4cnOR1-n7i9CYQ9wUC37yDpYlQ4j6rCfcsU/edit?tab=t.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d9c35c8115062f8f91024dabb290da02183a26877d6f60ace8c62884141c720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
